[
  {
    "status": "degraded",
    "affectedServices": "LOTUS2",
    "summary": "Regular scheduled maintenance day",
    "date": "2025-04-29T00:01",
    "updates": [
      {
        "date": "2025-02-28T13:00",
        "details": "Advance notice of regular scheduled maintenance day on Tues 29 April 2025. Please plan your work to minimise disruption."
      },
      {
        "date": "2025-04-29T17:00",
        "details": "Most maintenance work completed but some updates to LOTUS2 nodes to be completed tomorrow: this will impact job processing until more nodes can be made available. Further update to follow tomorrow."
      }
    ]
  },
  {
    "status": "degraded",
    "affectedServices": "PFS storage (/work/scratch-pw*, /work/xfc/*, /gws/pw/j07/*)",
    "summary": "I/O errors writing to PFS from within Slurm jobs",
    "date": "2025-04-03T13:00",
    "updates": [
      {
        "date": "2025-04-03T13:00",
        "details": "Issue reported where I/O errors occur when writing to PFS storage volumes from Slurm jobs. Appears to be memory-related: initial advice is to increase memory allocation for job. Investigation underway with vendor, awaiting further advice."
      },
      {
        "date": "2025-05-07T14:00",
        "details": "Investigation is still ongoing. Mitigation is to run on the non-PFS storage, e.g. /work/scratch-nopw2 for non-MPI read/write operations."
      }
    ]
  },
  {
    "status": "down",
    "affectedServices": "LOTUS1 ORCHID",
    "summary": "Earlier migration than planned",
    "date": "2025-04-25T08:30",
    "updates": [
      {
        "date": "2025-04-25T08:30",
        "details": "LOTUS1 ORCHID, including interactive GPU node gpuhost001, was planned to be fully migrated to Rocky 9 by Tuesday 29th April, but due to unforeseen circumstances this has been pushed to today."
      },
      {
        "date": "2025-04-29T15:00",
        "details": "LOTUS1 ORCHID & interactive GPU node migration is still in progress, but GPU notebooks are available."
      }
    ]
  }
]