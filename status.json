[
    {
    "status": "down",
    "affectedServices": "ALL Services",
    "summary": "Total network failure at RAL, all JASMIN and CEDA services down.",
    "date": "2025-04-04T09:00",
    "updates": [
      {
        "date": "2025-04-04T09:00",
        "details": "A total network failure at RAL means all JASMIN and CEDA services are down."
      }
    ]
  },
  {
    "status": "down",
    "affectedServices": "LOTUS (old cluster)",
    "summary": "Old cluster now retired for general use",
    "date": "2025-03-28T17:00",
    "updates": [
      {
        "date": "2025-03-28T17:00",
        "details": "As per recent announcements, the old cluster is now retired for general use. The new cluster is available for all users."
      }
    ]
  },
  {
    "status": "down",
    "affectedServices": "sci-ph-03",
    "summary": "Server reboot to clear performance issues",
    "date": "2025-04-01T14:00",
    "updates": [
      {
        "date": "2025-04-01T14:00",
        "details": "Server will be rebooted at 14:00 to clear performance issues."
      }
    ]
  },
  {
    "status": "resolved",
    "affectedServices": "sci-vm-*",
    "summary": "sci-vm hosts now submit to new cluster",
    "date": "2025-03-31T09:00",
    "updates": [
      {
        "date": "2025-03-31T09:00",
        "details": "sci-vm hosts have been switched over so that they now submit only to the new cluster."
      }
    ]
  },
  {
    "status": "down",
    "affectedServices": "All CEDA and JASMIN services",
    "summary": "Regular scheduled maintenance day",
    "date": "2025-04-29T00:01",
    "updates": [
      {
        "date": "2025-02-28T13:00",
        "details": "Advance notice of regular scheduled maintenance day on Tues 29 April 2025. Please plan your work to minimise disruption."
      }
    ]
  },
  {
    "status": "resolved",
    "affectedServices": "ORCHID GPU cluster",
    "summary": "ORCHID GPU cluster (batch nodes and interactive node) down for maintenance.",
    "date": "2025-04-02T00:01",
    "updates": [
      {
        "date": "2025-04-01T14:00",
        "details": "[POSTPONED] As part of work to move GPU nodes to Rocky 9 and a different part of the network, batch and interactive GPU nodes will be down for maintenance on [new date TBC]."
      }
    ]
  },
  {
    "status": "at risk",
    "affectedServices": "Object storage (HPOS)",
    "summary": "Maintenance work to switch proxy",
    "date": "2025-04-01T09:00",
    "updates": [
      {
        "date": "2025-03-28T09:45",
        "details": "Change should be transparent to users: no action needed."
      }
    ]
  },
  {
    "status": "degraded",
    "affectedServices": "PFS storage (/work/scratch-pw*, /work/xfc/*, /gws/pw/j07/*)",
    "summary": "I/O errors writing to PFS from within Slurm jobs",
    "date": "2025-04-03T13:00",
    "updates": [
      {
        "date": "2025-04-03T13:00",
        "details": "Issue reported where I/O errors occur when writing to PFS storage volumes from Slurm jobs. Appears to be memory-related: initial advice is to increase memory allocation for job. Investigation underway with vendor, awaiting further advice."
      }
    ]
  }
]
